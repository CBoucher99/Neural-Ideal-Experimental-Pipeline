{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecb24172-f7cb-44fe-95c9-844c46c516c5",
   "metadata": {},
   "source": [
    "Converting Raw DandiSet to Neural Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7846d94c-8d8d-4a12-afb7-24a575403cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neural_codewords(dandiset_id, filepath, min_unit, max_unit):\n",
    "    \n",
    "    # By Colleen Boucher\n",
    "    #Last edited: 4/10/22\n",
    "    #INPUT: dandiset_id (str), filepath (str), min_unit (int), max_unit (int)\n",
    "    #OUTPUT: File named \"neural_code_\"+dandiset_id + str(datetime.date.today()) +\".txt\" and saved \n",
    "    #        to the current folder\n",
    "    #SUMMARY: create_neural_codewords is a function that uses the streamed in the Dandiset and converts the \n",
    "    #electrophysiology data of the specified range of neurons into neural codewords to be read\n",
    "    #into the Neural Ideals SageMath package.\n",
    "\n",
    "    for i in range (min_unit,max_unit):\n",
    "        unit_number = i\n",
    "        spike_times = nwb.units[\"spike_times\"][unit_number]\n",
    "        bin_edges = np.arange(0, 183944, 1/1) #1 = 1 s; 1/100 = cs; 1/1000 = ms time binning\n",
    "        #183944 s is the total duration of recording that occured across all 3 units for the first\n",
    "        #data set tried\n",
    "        #should fix to specify start time as max start time across all units and stop time as min stop \n",
    "        #time across all units\n",
    "    \n",
    "        binary_spikes, tt = np.histogram(spike_times, bin_edges)\n",
    "\n",
    "        if i == min_unit:\n",
    "            matrix_code = binary_spikes\n",
    "        else:\n",
    "            matrix_code = np.vstack((matrix_code,binary_spikes))\n",
    "    \n",
    "        code_matrix = matrix_code.transpose()\n",
    "        \n",
    "    neural_code = \"\"\n",
    "    for j in range (0,len(code_matrix)):\n",
    "        codeword = \"\"\n",
    "        for i in range (0,max_unit-min_unit):\n",
    "            if code_matrix[j][i] != 0:\n",
    "                code_matrix[j][i] = 1\n",
    "            codeword = codeword + str(code_matrix[j][i])\n",
    "        \n",
    "            if i >= max_unit-min_unit-1:\n",
    "                codeword = codeword\n",
    "                neural_code = neural_code + codeword\n",
    "                break\n",
    "            \n",
    "        if j<len(code_matrix)-1:\n",
    "            neural_code = neural_code + \",\"\n",
    "            \n",
    "    file = open(\"neural_code_\"+dandiset_id + str(datetime.date.today()) +\".txt\", \"w\")\n",
    "    fContent = str(neural_code)\n",
    "\n",
    "    file.write(fContent)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50136a70-b6a6-4601-9cf0-d0ef5d652bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dandi.dandiapi import DandiAPIClient\n",
    "from pynwb import NWBHDF5IO\n",
    "from nwbwidgets import nwb2widget\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "dandiset_id, filepath = \"000005\", \"sub-anm184389/sub-anm184389_ses-20130213_behavior+ecephys.nwb\"\n",
    "\n",
    "with DandiAPIClient() as client:\n",
    "        asset = client.get_dandiset(dandiset_id, \"draft\").get_asset_by_path(filepath)\n",
    "        s3_url = asset.get_content_url(follow_redirects=1, strip_query=True)\n",
    "\n",
    "io = NWBHDF5IO(s3_url, mode='r', load_namespaces=True, driver='ros3')\n",
    "nwb = io.read()\n",
    "#nwb2widget(nwb) # Provides tabluar summary of the file's metadata\n",
    "#useful for determining a specific range of neurons to analyze\n",
    "\n",
    "min_unit, max_unit = 0, len(nwb.units)\n",
    "#min_unit and max_unit are to specify a range of neurons desired to be analysed for Dandisets\n",
    "#to convert the spike train data for a specific range of the neurons in the file use:\n",
    "#min_unit, max_unit = 22, 31\n",
    "\n",
    "create_neural_codewords(dandiset_id, filepath, min_unit, max_unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab985ae-7b37-4222-a4da-04eabce2f820",
   "metadata": {
    "tags": []
   },
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
